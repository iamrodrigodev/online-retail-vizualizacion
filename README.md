# Sistema de Visualizaci√≥n y An√°lisis de Datos de Retail Online
## Inteligencia de Negocios y Miner√≠a de Datos

<div align="center">
<table>
    <thead>
        <tr>
            <th>
                <img src="https://github.com/RodrigoStranger/imagenes-la-salle/blob/main/logo_secundario_color.png?raw=true" width="150"/>
            </th>
            <th>
                <span style="font-weight:bold;">UNIVERSIDAD LA SALLE DE AREQUIPA</span><br />
                <span style="font-weight:bold;">FACULTAD DE INGENIER√çAS Y ARQUITECTURA</span><br />
                <span style="font-weight:bold;">DEPARTAMENTO ACADEMICO DE INGENIER√çA Y MATEM√ÅTICAS</span><br />
                <span style="font-weight:bold;">CARRERA PROFESIONAL DE INGENIER√çA DE SOFTWARE</span>
            </th>
        </tr>
    </thead>
</table>
</div>

<div align="center">
<table>
    <thead>
        <tr>
            <th><strong>Semestre</strong></th>
            <th><strong>Profesor</strong></th>
            <th><strong>Cr√©ditos</strong></th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td align="center">2025 II</td>
            <td align="center">Ana Mar√≠a Cuadros Valdivia</td>
            <td align="center">3</td>
        </tr>
    </tbody>
</table>
</div>

---

## Tabla de Contenidos

1. [Descripci√≥n General](#descripci√≥n-general)
2. [Marco Te√≥rico](#marco-te√≥rico)
3. [Pipeline de Procesamiento y An√°lisis](#pipeline-de-procesamiento-y-an√°lisis)
4. [Modelos y Algoritmos Implementados](#modelos-y-algoritmos-implementados)
5. [Arquitectura del Sistema](#arquitectura-del-sistema)
6. [Comparaci√≥n con Enfoques Existentes](#comparaci√≥n-con-enfoques-existentes)
7. [Instalaci√≥n y Uso](#instalaci√≥n-y-uso)

---

## Descripci√≥n General

Este proyecto es una aplicaci√≥n web de inteligencia de negocios que implementa un **pipeline completo de miner√≠a de datos** para el an√°lisis de transacciones de retail online. El sistema combina t√©cnicas avanzadas de aprendizaje autom√°tico, an√°lisis estad√≠stico y visualizaci√≥n interactiva para extraer insights de negocio accionables.

### Objetivo Principal

Desarrollar un sistema integral de Business Intelligence que permita:
- Segmentaci√≥n autom√°tica de clientes basada en comportamiento de compra
- An√°lisis de similitud entre clientes usando algoritmos de Machine Learning
- Visualizaci√≥n interactiva de patrones de compra y tendencias de ventas
- Identificaci√≥n de productos estrella por segmento de cliente
- An√°lisis geogr√°fico de ventas y comportamiento de mercado

---

## üìä Descripci√≥n de los Datos

### Fuente del Dataset

**Nombre**: Online Retail Dataset
**Origen**: UCI Machine Learning Repository
**URL**: https://archive.ics.uci.edu/ml/datasets/Online+Retail
**Formato**: CSV (Comma-Separated Values)
**Tama√±o**: ~541,909 registros transaccionales
**Per√≠odo temporal**: 01/12/2010 - 09/12/2011 (13 meses)
**Alcance geogr√°fico**: 38 pa√≠ses

### Caracter√≠sticas del Dataset

El dataset representa transacciones de una tienda minorista en l√≠nea con sede en Reino Unido que vende principalmente regalos √∫nicos para todas las ocasiones. Los clientes incluyen tanto mayoristas como minoristas.

#### Variables del Dataset

| Variable | Tipo | Descripci√≥n | Ejemplo |
|----------|------|-------------|---------|
| `InvoiceNo` | String | N√∫mero √∫nico de factura (6 d√≠gitos). Las facturas que comienzan con 'C' indican cancelaciones | 536365 |
| `StockCode` | String | C√≥digo √∫nico del producto (5 d√≠gitos) | 85123A |
| `Description` | String | Nombre/descripci√≥n del producto | WHITE HANGING HEART T-LIGHT HOLDER |
| `Quantity` | Integer | Cantidad de cada producto por transacci√≥n. Valores negativos indican devoluciones | 6 |
| `InvoiceDate` | DateTime | Fecha y hora de la transacci√≥n | 2010-12-01 08:26:00 |
| `UnitPrice` | Float | Precio unitario del producto en Libras Esterlinas (¬£) | 2.55 |
| `CustomerID` | Float | Identificador √∫nico del cliente (5 d√≠gitos) | 17850.0 |
| `Country` | String | Nombre del pa√≠s de residencia del cliente | United Kingdom |
| `Category` | String | Categor√≠a principal del producto (agregada) | Home & Garden |
| `Subcategory` | String | Subcategor√≠a del producto (agregada) | Decorative Items |

**Nota**: Las columnas `Category` y `Subcategory` fueron agregadas mediante procesamiento adicional del dataset original.

### Caracter√≠sticas Estad√≠sticas del Dataset

#### Distribuci√≥n de Transacciones
- **Total de transacciones**: 541,909
- **Transacciones v√°lidas** (excluye cancelaciones y valores nulos): ~406,829
- **Clientes √∫nicos**: 4,372
- **Productos √∫nicos**: 4,070
- **Pa√≠ses representados**: 38 (90% de ventas concentradas en UK)

#### Distribuci√≥n Temporal
- **D√≠as con actividad**: 376 d√≠as
- **Transacciones promedio por d√≠a**: ~1,441
- **Mes con mayor actividad**: Noviembre 2011 (preparaci√≥n navide√±a)
- **Mes con menor actividad**: Diciembre 2010 (inicio del per√≠odo)

#### Distribuci√≥n por Pa√≠s (Top 5)
1. **United Kingdom**: 91.4% de transacciones
2. **Germany**: 2.3%
3. **France**: 1.9%
4. **EIRE (Ireland)**: 1.7%
5. **Spain**: 0.6%

#### Distribuci√≥n de Valores
- **Rango de precios**: ¬£0.00 - ¬£38,970.00
- **Precio promedio**: ¬£4.61
- **Cantidad promedio por transacci√≥n**: 9.55 unidades
- **Valor promedio de transacci√≥n**: ¬£22.35

### Calidad de los Datos

#### Valores Faltantes
| Variable | Valores Nulos | Porcentaje |
|----------|---------------|------------|
| CustomerID | 135,080 | 24.93% |
| Description | 1,454 | 0.27% |
| Otras variables | 0 | 0% |

#### Valores An√≥malos Detectados
- **Transacciones canceladas**: ~9,288 registros (InvoiceNo comienza con 'C')
- **Cantidades negativas**: Devoluciones de productos
- **Precios cero**: 1,580 registros (posibles promociones o errores)
- **Cantidades extremas**: Algunos pedidos mayoristas superan las 10,000 unidades

#### Limpieza Aplicada
Para los an√°lisis se excluyeron:
- Transacciones con `CustomerID` nulo (an√°lisis de clientes)
- Facturas de cancelaci√≥n (transacciones normales)
- Cantidades negativas (para an√°lisis de ventas positivas)
- Precios unitarios ‚â§ 0 (datos an√≥malos)

---

## üîß Pre-procesamiento de Datos

### Fase 1: Limpieza y Validaci√≥n

#### 1.1 Carga de Datos
```python
# Implementaci√≥n en dashboard/visualizations/shared/data_loader.py
@functools.lru_cache(maxsize=1)
def load_online_retail_data():
    url = "https://raw.githubusercontent.com/iamrodrigodev/online-retail/main/dataset/retail_with_categories.csv"
    df = pl.read_csv(url)
    return df
```

**Optimizaciones aplicadas**:
- Uso de **Polars** en lugar de Pandas (3-5x m√°s r√°pido para datasets grandes)
- **Cach√© en memoria** con `@lru_cache` (primera carga: ~2-5s, subsecuentes: <100ms)
- **Lazy loading**: Los datos solo se cargan cuando se solicitan

#### 1.2 Conversi√≥n de Tipos de Datos
```python
df = df.with_columns([
    pl.col('InvoiceDate').str.strptime(pl.Datetime, "%Y-%m-%d %H:%M:%S").alias('InvoiceDate')
])
```

**Transformaciones aplicadas**:
- `InvoiceDate`: String ‚Üí DateTime (permite operaciones temporales)
- `CustomerID`: Float ‚Üí String (para comparaciones exactas)
- `Quantity`: Integer validado (rechaza valores no num√©ricos)
- `UnitPrice`: Float validado (rechaza valores negativos)

#### 1.3 Creaci√≥n de Variables Derivadas
```python
df = df.with_columns([
    (pl.col('Quantity') * pl.col('UnitPrice')).alias('Total'),  # Total de la transacci√≥n
    (pl.col('Quantity') * pl.col('UnitPrice')).alias('Sales'),  # Ventas (para an√°lisis)
    pl.col('InvoiceDate').dt.date().alias('Fecha'),             # Fecha sin hora
    pl.col('InvoiceDate').dt.year().alias('A√±o'),               # A√±o de la transacci√≥n
    pl.col('InvoiceDate').dt.month().alias('Mes')               # Mes de la transacci√≥n
])
```

**Variables derivadas creadas**:
- **Total/Sales**: Monto monetario de cada l√≠nea de transacci√≥n
- **Fecha**: Fecha sin componente de hora (para agregaciones diarias)
- **A√±o/Mes**: Componentes temporales para an√°lisis de tendencias

### Fase 2: Filtrado y Segmentaci√≥n

#### 2.1 Filtros Aplicables
El sistema permite filtrado din√°mico por:
- **Pa√≠s**: Filtro categ√≥rico sobre `Country`
- **Rango de fechas**: Filtro temporal (`YYYY-MM` formato)
- **Perfil de cliente**: Filtro basado en segmentaci√≥n RFM

#### 2.2 Manejo de Valores Faltantes
**Estrategia adoptada**:
- **CustomerID nulo**: Se excluyen para an√°lisis de clientes (RFM, similitud)
- **Description nulo**: Se reemplaza con "Sin descripci√≥n"
- **Otros campos**: No se permiten nulos (integridad referencial)

### Fase 3: Feature Engineering para RFM

#### 3.1 C√°lculo de M√©tricas RFM
```python
# Fecha de referencia: 1 d√≠a despu√©s de la √∫ltima transacci√≥n
reference_date = df['InvoiceDate'].max() + timedelta(days=1)

rfm = df.group_by('CustomerID').agg([
    # Recency: D√≠as desde √∫ltima compra
    ((reference_date - pl.col('InvoiceDate').max()).dt.days()).alias('Recency'),

    # Frequency: N√∫mero de transacciones √∫nicas
    pl.col('InvoiceNo').n_unique().alias('Frequency'),

    # Monetary: Suma total de ventas
    pl.col('Sales').sum().alias('Monetary'),

    # M√©tricas adicionales
    pl.col('Quantity').sum().alias('TotalQuantity'),
    pl.col('UnitPrice').mean().alias('AvgUnitPrice'),
    pl.col('StockCode').n_unique().alias('UniqueProducts')
])
```

**M√©tricas calculadas**:
1. **Recency (R)**: D√≠as transcurridos desde la √∫ltima compra
   - F√≥rmula: `Fecha_Referencia - MAX(InvoiceDate_cliente)`
   - Interpretaci√≥n: Valores bajos = clientes activos

2. **Frequency (F)**: N√∫mero de transacciones distintas
   - F√≥rmula: `COUNT(DISTINCT InvoiceNo)`
   - Interpretaci√≥n: Valores altos = clientes leales

3. **Monetary (M)**: Valor total de compras
   - F√≥rmula: `SUM(Quantity √ó UnitPrice)`
   - Interpretaci√≥n: Valores altos = clientes valiosos

4. **TotalQuantity**: Volumen total de productos
   - F√≥rmula: `SUM(Quantity)`
   - Uso: Distinguir mayoristas de minoristas

5. **AvgUnitPrice**: Precio promedio de productos
   - F√≥rmula: `AVG(UnitPrice)`
   - Uso: Identificar segmento premium vs. est√°ndar

6. **UniqueProducts**: Diversidad de productos
   - F√≥rmula: `COUNT(DISTINCT StockCode)`
   - Uso: Amplitud de inter√©s del cliente

7. **AvgOrderValue (AOV)**: Valor promedio por pedido
   - F√≥rmula: `Monetary / Frequency`
   - Uso: Tama√±o t√≠pico de compra

#### 3.2 Segmentaci√≥n de Clientes mediante IQR

**M√©todo estad√≠stico**: Interquartile Range (IQR) para detecci√≥n de outliers

```python
def detectar_outliers_iqr(df, columna):
    Q1 = df[columna].quantile(0.25)
    Q3 = df[columna].quantile(0.75)
    IQR = Q3 - Q1
    upper_bound = Q3 + 1.5 * IQR
    return upper_bound
```

**Clasificaci√≥n de perfiles** (4 segmentos):

| Perfil | Condici√≥n Total | Condici√≥n UnitPrice | Interpretaci√≥n |
|--------|-----------------|---------------------|----------------|
| **Minorista Est√°ndar** | Total ‚â§ Q3 | UnitPrice ‚â§ Q3 | Cliente casual, productos masivos |
| **Mayorista Est√°ndar** | Total > Q3 + 1.5√óIQR | UnitPrice ‚â§ Q3 | Revendedor, compras en volumen |
| **Minorista Lujo** | Total ‚â§ Q3 | UnitPrice > Q3 + 1.5√óIQR | Cliente premium, productos selectos |
| **Mayorista Lujo** | Total > Q3 + 1.5√óIQR | UnitPrice > Q3 + 1.5√óIQR | Distribuidor de alta gama |

**Ventajas del m√©todo IQR**:
- ‚úÖ **Robusto**: No asume distribuci√≥n normal (datos de retail son asim√©tricos)
- ‚úÖ **Adaptativo**: Se ajusta autom√°ticamente a la distribuci√≥n de cada dataset
- ‚úÖ **Interpretable**: Umbrales claros basados en cuartiles estad√≠sticos
- ‚úÖ **No param√©trico**: Funciona con cualquier distribuci√≥n de datos

### Fase 4: Normalizaci√≥n para Machine Learning

#### 4.1 Z-Score (Estandarizaci√≥n)
```python
def normalize_zscore(features):
    mean = np.mean(features, axis=0)
    std = np.std(features, axis=0)
    normalized = (features - mean) / (std + 1e-10)  # epsilon para evitar divisi√≥n por cero
    return normalized.astype(np.float32)
```

**Propiedades**:
- Transforma a distribuci√≥n con Œº=0, œÉ=1
- Preserva informaci√≥n sobre outliers
- **Recomendado** para algoritmos basados en distancias (KNN, K-Means)

#### 4.2 Min-Max (Escalado [0,1])
```python
def normalize_minmax(features):
    min_val = np.min(features, axis=0)
    max_val = np.max(features, axis=0)
    normalized = (features - min_val) / (max_val - min_val + 1e-10)
    return normalized.astype(np.float32)
```

**Propiedades**:
- Escala todos los valores al rango [0, 1]
- Sensible a outliers extremos
- √ötil cuando se requiere interpretabilidad directa

### Fase 5: Optimizaciones de Performance

#### 5.1 Reducci√≥n de Memoria
- **Uso de float32** en lugar de float64 (50% menos memoria)
- **Operaciones in-place** de NumPy (evita copias innecesarias)
- **Garbage collection agresivo** despu√©s de operaciones pesadas

```python
import gc
features = features.astype(np.float32)  # Reducci√≥n de memoria
gc.collect()  # Liberar memoria no utilizada
```

#### 5.2 Optimizaci√≥n de C√°lculos
- **Broadcasting de NumPy**: Operaciones vectorizadas evitan loops de Python
- **Polars lazy evaluation**: Optimizaci√≥n autom√°tica de queries
- **Algoritmos eficientes**: Elkan para K-Means, Randomized SVD para PCA

---

## üìà Tareas de An√°lisis

### Tarea 1: An√°lisis Geogr√°fico de Ventas

**Objetivo**: Identificar patrones de ventas por pa√≠s y detectar mercados clave.

**M√©todo**: Agregaci√≥n de ventas totales por pa√≠s con visualizaci√≥n de coropleta.

**Implementaci√≥n**:
```python
sales_by_country = df.group_by('Country').agg([
    pl.col('Sales').sum().alias('TotalSales'),
    pl.col('InvoiceNo').n_unique().alias('TotalTransactions'),
    pl.col('CustomerID').n_unique().alias('UniqueCustomers')
]).sort('TotalSales', descending=True)
```

**Insights obtenidos**:
- Reino Unido domina con 91.4% de las ventas totales
- Alemania y Francia son mercados secundarios importantes
- 35 pa√≠ses contribuyen menos del 5% de ventas (long tail)

**Visualizaci√≥n**: Mapa coropleta interactivo (Plotly Choropleth)

---

### Tarea 2: Segmentaci√≥n de Clientes (RFM)

**Objetivo**: Clasificar clientes en segmentos accionables para estrategias de marketing diferenciadas.

**M√©todo**: An√°lisis RFM extendido con detecci√≥n de outliers IQR en dos dimensiones (Total y UnitPrice).

**Algoritmo**:
1. Calcular m√©tricas RFM base para cada cliente
2. Detectar umbrales IQR en `Total` de transacciones
3. Detectar umbrales IQR en `UnitPrice` promedio
4. Clasificar en matriz 2√ó2 (Volumen √ó Precio)

**Resultados** (distribuci√≥n t√≠pica):
- **Minorista Est√°ndar**: ~70% de clientes (base del negocio)
- **Mayorista Est√°ndar**: ~15% (alto volumen, productos masivos)
- **Minorista Lujo**: ~10% (bajo volumen, alto valor unitario)
- **Mayorista Lujo**: ~5% (clientes premium de alto valor)

**Aplicaciones de negocio**:
- Campa√±as de email marketing segmentadas
- Programas de lealtad diferenciados
- Recomendaciones de productos personalizadas
- Estrategias de retenci√≥n espec√≠ficas por segmento

---

### Tarea 3: An√°lisis de Similitud de Clientes (KNN + PCA + K-Means)

**Objetivo**: Identificar grupos de clientes con comportamiento similar para recomendaciones y micro-segmentaci√≥n.

**Pipeline de Machine Learning**:

#### 3.1 Preparaci√≥n de Caracter√≠sticas (7 dimensiones)
- Recency, Frequency, Monetary
- TotalQuantity, AvgUnitPrice, AvgOrderValue, UniqueProducts

#### 3.2 Normalizaci√≥n
- M√©todo predeterminado: **Z-Score**
- Convierte caracter√≠sticas a escala comparable

#### 3.3 C√°lculo de Matriz de Distancias
**M√©tricas disponibles**:

1. **Euclidiana** (predeterminada):
   ```
   d(x,y) = ‚àö(Œ£·µ¢ (x·µ¢ - y·µ¢)¬≤)
   ```
   - Sensible a magnitud absoluta
   - Ideal para similitud cuantitativa

2. **Coseno**:
   ```
   d(x,y) = 1 - (x¬∑y) / (||x|| ¬∑ ||y||)
   ```
   - Mide similitud de patrones (√°ngulo entre vectores)
   - Invariante a escala

3. **Pearson**:
   ```
   d(x,y) = 1 - correlation(x,y)
   ```
   - Captura correlaci√≥n lineal
   - Robusto ante transformaciones lineales

#### 3.4 K-Nearest Neighbors (KNN)
**Par√°metros**:
- **k**: N√∫mero de vecinos (configurable 1-500, recomendado: 10-20)
- **Output**: Grafo dirigido donde cada cliente se conecta a sus k vecinos m√°s cercanos

**Aplicaciones**:
- Recomendaci√≥n de productos basada en vecinos similares
- Detecci√≥n de micro-segmentos dentro de perfiles RFM
- Identificaci√≥n de "clientes semilla" para campa√±as

#### 3.5 Reducci√≥n Dimensional (PCA)
**Algoritmo**: Principal Component Analysis via Randomized SVD

```python
from sklearn.decomposition import PCA
pca = PCA(n_components=2, svd_solver='randomized', random_state=42)
embedding_2d = pca.fit_transform(features_normalized)
```

**Resultados t√≠picos**:
- **PC1** (30-40% varianza): Captura principalmente Monetary y AvgOrderValue
- **PC2** (20-30% varianza): Captura Frequency y Recency
- **Total preservado**: ~60-70% de informaci√≥n original

**Ventajas**:
- Visualizaci√≥n humana de 7 dimensiones ‚Üí 2D
- Mantiene relaciones de similitud aproximadas
- Facilita identificaci√≥n de clusters y outliers

#### 3.6 Clustering K-Means
**Configuraci√≥n**:
```python
from sklearn.cluster import KMeans
kmeans = KMeans(
    n_clusters=4,           # Alineado con 4 perfiles RFM
    algorithm='elkan',      # M√°s eficiente que Lloyd
    n_init=5,              # M√∫ltiples inicializaciones
    max_iter=50,           # Balance convergencia/velocidad
    random_state=42
)
```

**Funci√≥n objetivo**: Minimizar WCSS (Within-Cluster Sum of Squares)
```
WCSS = Œ£‚±º Œ£_{x‚ààC‚±º} ||x - Œº‚±º||¬≤
```

**Interpretaci√≥n de clusters**:
- Los 4 clusters **NO son id√©nticos** a los 4 perfiles RFM
- Clusters capturan patrones en 7 dimensiones (vs. 2 del RFM)
- Complementan la segmentaci√≥n de negocio con agrupamiento anal√≠tico

#### 3.7 Detecci√≥n de Outliers
**M√©todo**: Z-Score multidimensional

```python
z_scores = np.abs((features - np.mean(features, axis=0)) / np.std(features, axis=0))
outliers = np.any(z_scores > 3, axis=1)  # Outlier si CUALQUIER dimensi√≥n excede 3œÉ
```

**Threshold**: 3 desviaciones est√°ndar (captura ~0.3% m√°s extremo)

**Visualizaci√≥n**:
- Outliers: Marcador de diamante, tama√±o mayor, borde negro
- Normales: C√≠rculos, color por cluster

**Valor de negocio**:
- Identificar clientes VIP con comportamiento excepcional
- Detectar casos especiales que requieren atenci√≥n personalizada
- Validar anomal√≠as (posibles errores vs. oportunidades reales)

---

### Tarea 4: An√°lisis de Tendencias de Ventas

**Objetivo**: Identificar patrones temporales, estacionalidad y anomal√≠as en las ventas.

**M√©todo**: Agregaci√≥n temporal con an√°lisis de series de tiempo.

**Granularidades analizadas**:
- **Diaria**: Detecci√≥n de picos y valles espec√≠ficos
- **Mensual**: Identificaci√≥n de estacionalidad
- **Anual**: Comparaci√≥n interanual (cuando disponible)

**M√©tricas calculadas por d√≠a**:
```python
daily_sales = df.group_by('Fecha').agg([
    pl.col('Sales').sum().alias('TotalSales'),
    pl.col('InvoiceNo').n_unique().alias('Transactions'),
    pl.col('CustomerID').n_unique().alias('UniqueCustomers'),
    pl.col('Quantity').sum().alias('TotalQuantity'),
    pl.col('StockCode').n_unique().alias('UniqueProducts')
])
```

**An√°lisis de anomal√≠as**:
- Detecci√≥n de outliers temporales mediante IQR
- D√≠as excepcionales (>percentil 95)
- D√≠as an√≥malos (<percentil 5)

**Insights generados autom√°ticamente**:
- Comparaci√≥n d√≠a anterior (variaci√≥n %)
- Comparaci√≥n promedio mensual
- Comparaci√≥n misma semana anterior
- Comparaci√≥n interanual (si disponible)

---

### Tarea 5: An√°lisis de Productos

**Objetivo**: Identificar productos estrella, categor√≠as dominantes y oportunidades de cross-selling.

**M√©todo**: Ranking por ventas totales con filtros din√°micos.

**An√°lisis realizados**:

#### 5.1 Top Productos Globales
```python
top_products = df.group_by(['StockCode', 'Description']).agg([
    pl.col('Quantity').sum().alias('TotalQuantity'),
    pl.col('Sales').sum().alias('TotalSales'),
    pl.col('CustomerID').n_unique().alias('UniqueCustomers')
]).sort('TotalSales', descending=True).head(10)
```

#### 5.2 Top Productos por Segmento de Cliente
- Filtrado por perfil RFM antes de agregaci√≥n
- Identifica preferencias espec√≠ficas por segmento

#### 5.3 Top Productos por Pa√≠s
- Revela diferencias culturales en preferencias
- √ötil para localizaci√≥n de inventario

#### 5.4 An√°lisis por Categor√≠a/Subcategor√≠a
- Jerarqu√≠a de dos niveles
- Identificaci√≥n de categor√≠as de alto rendimiento

**Aplicaciones de negocio**:
- Optimizaci√≥n de inventario
- Estrategias de promoci√≥n
- Bundling de productos complementarios
- Descontinuaci√≥n de productos de bajo rendimiento

---

### Tarea 6: Sistema de Insights Autom√°ticos (Contribuci√≥n Nueva)

**Objetivo**: Generar explicaciones autom√°ticas basadas en reglas de negocio para cada d√≠a analizado.

**M√©todo**: Sistema de reglas condicionales aplicadas sobre m√©tricas calculadas.

**Reglas implementadas** (8 tipos de insights):

1. **D√≠a excepcional**: `ventas_d√≠a > 1.5 √ó promedio_mes`
2. **Alerta de bajo rendimiento**: `ventas_d√≠a < 0.5 √ó promedio_mes`
3. **Patr√≥n de fin de semana**: `d√≠a_semana ‚â• 5 AND ventas > promedio + 20%`
4. **Concentraci√≥n de ventas**: `top_cliente > 30% del total_d√≠a`
5. **Perfil premium dominante**: `‚â•3 de top_5 clientes son Lujo`
6. **Actividad mayorista**: `‚â•4 de top_5 clientes son Mayoristas`
7. **Tendencia alcista/bajista**: Crecimiento/ca√≠da en d√≠a anterior Y semana anterior
8. **Crecimiento interanual**: `ventas_a√±o_actual > 2 √ó ventas_a√±o_anterior`

**Output**: Mensajes contextuales con iconos y colores seg√∫n tipo:
- üü¢ **Success**: Rendimiento excepcional
- üü° **Warning**: Alertas que requieren atenci√≥n
- üîµ **Info**: Patrones y observaciones neutrales

**Valor agregado**:
- Automatiza la interpretaci√≥n de datos (reduce tiempo de an√°lisis)
- Democratiza el acceso a insights (usuarios no t√©cnicos)
- Facilita la toma de decisiones informadas
- Genera hip√≥tesis para investigaci√≥n profunda

---

## Marco Te√≥rico

### 1. An√°lisis RFM (Recency, Frequency, Monetary)

El an√°lisis RFM es una t√©cnica de marketing cuantitativo que segmenta clientes seg√∫n tres dimensiones clave:

#### 1.1 Fundamento Te√≥rico

**Recency (R)**: Tiempo transcurrido desde la √∫ltima compra del cliente.
- **Base te√≥rica**: Los clientes que compraron recientemente tienen mayor probabilidad de volver a comprar (teor√≠a de comportamiento del consumidor).
- **F√≥rmula**: `R = Fecha_Referencia - √öltima_Fecha_Compra` (en d√≠as)
- **Interpretaci√≥n**: Valores bajos de R indican clientes activos.

**Frequency (F)**: N√∫mero de transacciones realizadas por el cliente.
- **Base te√≥rica**: La frecuencia de compra est√° correlacionada con la lealtad del cliente.
- **F√≥rmula**: `F = Conteo de transacciones √∫nicas (InvoiceNo)`
- **Interpretaci√≥n**: Valores altos de F indican clientes leales y comprometidos.

**Monetary (M)**: Valor total de las compras del cliente.
- **Base te√≥rica**: El valor monetario indica el potencial de ingresos del cliente (Customer Lifetime Value).
- **F√≥rmula**: `M = Suma(Quantity √ó UnitPrice)` para todas las transacciones
- **Interpretaci√≥n**: Valores altos de M identifican clientes de alto valor.

#### 1.2 M√©tricas Complementarias

Adem√°s del RFM tradicional, nuestro modelo incluye:

- **TotalQuantity**: Volumen total de productos comprados (distingue entre compradores mayoristas y minoristas)
- **AvgUnitPrice**: Precio promedio de productos comprados (identifica segmentos de lujo vs. est√°ndar)
- **AvgOrderValue**: Valor promedio por transacci√≥n (AOV = Monetary / Frequency)
- **UniqueProducts**: Diversidad de productos comprados (indica amplitud del inter√©s del cliente)

**Justificaci√≥n**: Estas m√©tricas adicionales capturan dimensiones del comportamiento del cliente que el RFM tradicional no contempla, permitiendo una segmentaci√≥n m√°s granular y precisa.

### 2. Detecci√≥n de Outliers mediante IQR (Interquartile Range)

#### 2.1 Fundamento Matem√°tico

El m√©todo IQR es una t√©cnica estad√≠stica robusta para identificar valores at√≠picos basada en cuartiles:

**Definiciones**:
- Q1 (Primer Cuartil): Valor que divide el 25% inferior de los datos
- Q3 (Tercer Cuartil): Valor que divide el 75% inferior de los datos
- IQR = Q3 - Q1 (Rango intercuart√≠lico)

**L√≠mites de Detecci√≥n**:
```
L√≠mite_Inferior = Q1 - 1.5 √ó IQR
L√≠mite_Superior = Q3 + 1.5 √ó IQR
```

#### 2.2 Aplicaci√≥n en Segmentaci√≥n de Clientes

En nuestro modelo, aplicamos IQR en dos dimensiones:

1. **Total de Transacci√≥n**: Identifica compras mayoristas vs. minoristas
2. **Precio Unitario**: Identifica productos de lujo vs. est√°ndar

**Clasificaci√≥n de Perfiles** (4 segmentos):

| Perfil | Condici√≥n Total | Condici√≥n UnitPrice | Interpretaci√≥n de Negocio |
|--------|-----------------|---------------------|---------------------------|
| Minorista Est√°ndar | ‚â§ Q3_Total | ‚â§ Q3_UnitPrice | Cliente casual, productos masivos |
| Mayorista Est√°ndar | > Q3_Total | ‚â§ Q3_UnitPrice | Revendedor, compras en volumen |
| Minorista Lujo | ‚â§ Q3_Total | > Q3_UnitPrice | Cliente premium, productos selectos |
| Mayorista Lujo | > Q3_Total | > Q3_UnitPrice | Distribuidor de alta gama |

**Ventaja sobre m√©todos param√©tricos**: IQR no asume distribuci√≥n normal de los datos, siendo robusto ante asimetr√≠a (com√∫n en datos de retail).

**Implementaci√≥n en c√≥digo** (`customer_profiles/data_processor.py:detectar_outliers_iqr`):
```python
def detectar_outliers_iqr(df, columna):
    Q1 = df[columna].quantile(0.25)
    Q3 = df[columna].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return lower_bound, upper_bound
```

### 3. Normalizaci√≥n de Datos

La normalizaci√≥n es crucial antes de aplicar algoritmos de distancia y clustering. Implementamos dos m√©todos:

#### 3.1 Z-Score (Estandarizaci√≥n)

**F√≥rmula**:
```
X_normalized = (X - Œº) / œÉ
```
Donde:
- Œº = media de la caracter√≠stica
- œÉ = desviaci√≥n est√°ndar

**Propiedades**:
- Transforma datos a distribuci√≥n con Œº=0 y œÉ=1
- Preserva la forma de la distribuci√≥n original
- Mantiene informaci√≥n sobre outliers

**Cu√°ndo usar**:
- Para algoritmos basados en distancias (KNN, K-Means)
- Cuando las caracter√≠sticas tienen escalas muy diferentes (ej: Recency en d√≠as vs. Monetary en d√≥lares)
- Para visualizaci√≥n de clustering (mejor separaci√≥n visual)

#### 3.2 Min-Max (Escalado a [0,1])

**F√≥rmula**:
```
X_normalized = (X - X_min) / (X_max - X_min)
```

**Propiedades**:
- Escala todos los valores al rango [0, 1]
- Preserva la forma de la distribuci√≥n
- Sensible a outliers (pueden comprimir la distribuci√≥n)

**Cu√°ndo usar**:
- Para algoritmos que requieren rangos acotados
- Cuando se necesita interpretabilidad directa (porcentajes)

**Recomendaci√≥n del sistema**: Usar **Z-Score por defecto** para mejores resultados de clustering y visualizaci√≥n.

### 4. M√©tricas de Distancia

Las m√©tricas de distancia cuantifican la similitud entre clientes en el espacio de caracter√≠sticas RFM.

#### 4.1 Distancia Euclidiana

**F√≥rmula**:
```
d(x, y) = ‚àö(Œ£·µ¢ (x·µ¢ - y·µ¢)¬≤)
```

**Interpretaci√≥n Geom√©trica**: Distancia en l√≠nea recta en el espacio n-dimensional.

**Propiedades**:
- M√©trica m√°s intuitiva y com√∫n
- Sensible a la magnitud absoluta de las diferencias
- Asume que todas las dimensiones son igualmente importantes

**Ventajas**:
- Computacionalmente eficiente: O(n¬≤¬∑m) donde n=clientes, m=caracter√≠sticas
- F√°cil de interpretar
- Funciona bien cuando las caracter√≠sticas est√°n normalizadas

**Aplicaci√≥n**: √ötil para encontrar clientes con patrones de compra **cuantitativamente similares**.

#### 4.2 Distancia Coseno

**F√≥rmula**:
```
similarity(x, y) = (x ¬∑ y) / (||x|| ¬∑ ||y||)
distance(x, y) = 1 - similarity(x, y)
```

**Interpretaci√≥n Geom√©trica**: Mide el √°ngulo entre vectores (0¬∞ = id√©nticos, 90¬∞ = ortogonales).

**Propiedades**:
- Invariante a la magnitud (solo considera direcci√≥n)
- Rango: [0, 2] (0 = id√©nticos, 2 = opuestos)
- Popular en sistemas de recomendaci√≥n

**Ventajas**:
- Captura similitud de **patrones relativos** (proporciones)
- Un cliente que gasta $1000 con patr√≥n RFM similar a otro que gasta $100 ser√°n considerados similares

**Aplicaci√≥n**: Ideal para identificar clientes con **comportamientos proporcionales** independientemente de la escala.

#### 4.3 Distancia de Pearson

**F√≥rmula**:
```
correlation(x, y) = Œ£·µ¢((x·µ¢ - xÃÑ)(y·µ¢ - »≥)) / (n ¬∑ œÉ‚Çì ¬∑ œÉ·µß)
distance(x, y) = 1 - correlation(x, y)
```

**Interpretaci√≥n**: Basada en la correlaci√≥n de Pearson (-1 a 1, transformada a distancia).

**Propiedades**:
- Mide correlaci√≥n lineal entre caracter√≠sticas
- Normaliza por media y desviaci√≥n est√°ndar
- Rango: [0, 2] (0 = correlaci√≥n perfecta positiva)

**Ventajas**:
- Captura relaciones lineales entre caracter√≠sticas
- Robusto ante transformaciones lineales (escala y traslaci√≥n)

**Aplicaci√≥n**: √ötil para identificar clientes con **tendencias correlacionadas** en su comportamiento.

**Comparaci√≥n pr√°ctica**:

| M√©trica | Sensibilidad a Magnitud | Interpretaci√≥n | Mejor Para |
|---------|-------------------------|----------------|------------|
| Euclidiana | Alta | Diferencias absolutas | Valores cuantitativos |
| Coseno | Nula | Similitud de patrones | Comportamientos proporcionales |
| Pearson | Baja | Correlaci√≥n lineal | Tendencias y relaciones |

### 5. K-Nearest Neighbors (KNN)

#### 5.1 Algoritmo

KNN es un m√©todo de aprendizaje supervisado (en clasificaci√≥n) y no supervisado (en grafos de similitud).

**Funcionamiento**:
1. Calcular matriz de distancias D entre todos los pares de clientes: O(n¬≤¬∑m)
2. Para cada cliente i, ordenar distancias: O(n log n)
3. Seleccionar los k clientes m√°s cercanos (menores distancias)
4. Crear aristas (edges) entre cliente i y sus k vecinos

**Complejidad temporal**: O(n¬≤¬∑m + n¬≤¬∑log n) ‚âà O(n¬≤¬∑m) para n clientes y m caracter√≠sticas.

#### 5.2 Par√°metro k

La elecci√≥n de k es cr√≠tica:

- **k peque√±o** (k=3-5): Alta sensibilidad a ruido, grafos dispersos
- **k medio** (k=10-20): Balance entre sensibilidad y robustez (recomendado)
- **k grande** (k>50): Grafos densos, pierde especificidad

**Selecci√≥n adaptativa en el sistema**: k configurable entre 1 y 500.

#### 5.3 Construcci√≥n del Grafo de Similitud

El grafo resultante G = (V, E) tiene:
- **V√©rtices (V)**: Clientes
- **Aristas (E)**: Conexiones entre cliente y sus k vecinos m√°s cercanos
- **Propiedades**: Dirigido (puede que j ‚àà KNN(i) pero i ‚àâ KNN(j))

**Aplicaci√≥n en BI**:
- Identificar "clientes semilla" para campa√±as de marketing
- Recomendaciones de productos basadas en vecinos similares
- Detecci√≥n de micro-segmentos dentro de perfiles RFM

### 6. PCA (Principal Component Analysis)

#### 6.1 Fundamento Matem√°tico

PCA es una t√©cnica de reducci√≥n dimensional que proyecta datos de alta dimensi√≥n a un subespacio de menor dimensi√≥n maximizando la varianza preservada.

**Objetivo**: Encontrar direcciones (componentes principales) que capturan la mayor variabilidad de los datos.

**Algoritmo** (via SVD - Singular Value Decomposition):

1. **Centrar datos**: X_centered = X - mean(X)
2. **Calcular matriz de covarianza**: C = (1/n) ¬∑ X_centered^T ¬∑ X_centered
3. **Descomposici√≥n en valores singulares**: X_centered = U ¬∑ Œ£ ¬∑ V^T
4. **Componentes principales**: PC = V (vectores propios de C)
5. **Proyecci√≥n**: X_reduced = X_centered ¬∑ PC[:, :k]

#### 6.2 Varianza Explicada

**M√©trica clave**: Proporci√≥n de varianza explicada por cada componente.

```
Varianza_explicada_i = Œª·µ¢ / Œ£‚±º Œª‚±º
```

Donde Œª·µ¢ son los valores propios de la matriz de covarianza.

**Interpretaci√≥n**:
- PC1 (30-40%): Captura la direcci√≥n de m√°xima variabilidad (usualmente dominada por Monetary)
- PC2 (20-30%): Segunda direcci√≥n ortogonal (usualmente Frequency o Recency)
- Total 2 componentes: ~60-70% de informaci√≥n preservada

#### 6.3 Loadings (Pesos de Caracter√≠sticas)

Los **loadings** indican la contribuci√≥n de cada caracter√≠stica original a cada componente principal.

**F√≥rmula**:
```
Loading_ij = correlaci√≥n(Feature_i, PC_j)
```

**Interpretaci√≥n** en nuestro sistema:

Por ejemplo, si PC1 tiene loadings:
- Monetary: 0.85 (contribuci√≥n alta positiva)
- AvgOrderValue: 0.75
- Frequency: 0.45
- Recency: -0.30 (contribuci√≥n negativa)

**Significado**: PC1 representa principalmente el "valor del cliente" (combinaci√≥n de gasto total y frecuencia, inversamente relacionado con recencia).

#### 6.4 Visualizaci√≥n 2D

**Reducci√≥n a 2D** (de 7 dimensiones originales):
- Permite visualizaci√≥n humana de patrones complejos
- Preserva relaciones de similitud aproximadas
- Facilita identificaci√≥n de clusters y outliers

**Trade-off**:
- ‚úÖ Ganancia: Interpretabilidad visual
- ‚ö†Ô∏è P√©rdida: ~30-40% de informaci√≥n (varianza no capturada por PC1 y PC2)

**Optimizaci√≥n implementada**:
- Uso de **randomized SVD** (m√°s r√°pido para datasets grandes)
- Tipo de dato **float32** (ahorra 50% de memoria vs float64)

### 7. K-Means Clustering

#### 7.1 Algoritmo

K-Means es un algoritmo de clustering particional que agrupa datos en k clusters minimizando la varianza intra-cluster.

**Algoritmo de Lloyd** (implementaci√≥n est√°ndar):

```
1. Inicializaci√≥n: Seleccionar k centroides aleatorios (k-means++)
2. Asignaci√≥n: Asignar cada punto al centroide m√°s cercano
   cluster(x) = argmin_j ||x - Œº‚±º||¬≤
3. Actualizaci√≥n: Recalcular centroides como promedio de puntos asignados
   Œº‚±º = (1/|C‚±º|) ¬∑ Œ£_{x ‚àà C‚±º} x
4. Repetir pasos 2-3 hasta convergencia (cambio < Œµ) o max_iter
```

**Complejidad**: O(n ¬∑ k ¬∑ m ¬∑ t) donde t = n√∫mero de iteraciones (t√≠picamente 10-50).

#### 7.2 Funci√≥n Objetivo

K-Means minimiza la **suma de cuadrados intra-cluster** (Within-Cluster Sum of Squares, WCSS):

```
WCSS = Œ£‚±º Œ£_{x ‚àà C‚±º} ||x - Œº‚±º||¬≤
```

**Interpretaci√≥n**: Busca clusters compactos (puntos cercanos a su centroide).

#### 7.3 Selecci√≥n de k

En nuestro sistema, **k=4 clusters** se elige estrat√©gicamente para:

1. **Alineaci√≥n con perfiles de negocio**: 4 clusters corresponden a los 4 perfiles RFM (Minorista/Mayorista √ó Est√°ndar/Lujo)
2. **Interpretabilidad**: N√∫mero manejable de segmentos para estrategias de marketing
3. **Validaci√≥n emp√≠rica**: El m√©todo Elbow y Silhouette Score sugieren k=4-5 como √≥ptimo para este dataset

#### 7.4 Optimizaciones Implementadas

- **Algoritmo Elkan**: M√°s eficiente que Lloyd est√°ndar, evita c√°lculos redundantes
- **n_init=5**: M√∫ltiples inicializaciones aleatorias (evita m√≠nimos locales)
- **max_iter=50**: L√≠mite de iteraciones (balance entre convergencia y velocidad)
- **float32**: Reduce uso de memoria cr√≠tico en producci√≥n

#### 7.5 Diferencia con Clasificaci√≥n RFM

**Punto clave**: Los 4 clusters de K-Means NO son id√©nticos a los 4 perfiles RFM:

| Aspecto | Perfiles RFM (IQR) | Clusters K-Means |
|---------|-------------------|------------------|
| M√©todo | Reglas determin√≠sticas (outliers IQR) | Optimizaci√≥n iterativa (WCSS) |
| Dimensiones usadas | 2 (Total, UnitPrice) | 7 (RFM + 4 m√©tricas) |
| Fronteras | Lineales (cuartiles) | No lineales (distancias euclidianas) |
| Interpretaci√≥n | Tipos de cliente (negocio) | Grupos de comportamiento (datos) |

**Sinergia**:
- **Perfiles RFM**: Segmentaci√≥n de negocio (tooltip, validaci√≥n)
- **Clusters K-Means**: Segmentaci√≥n anal√≠tica (visualizaci√≥n, colores)

### 8. Detecci√≥n de Outliers Estad√≠sticos

#### 8.1 M√©todo Z-Score

**F√≥rmula**:
```
z_score(x) = |x - Œº| / œÉ
Outlier si max(z_score(x)) > threshold (default: 3)
```

**Regla emp√≠rica** (distribuci√≥n normal):
- 68% de datos dentro de 1œÉ
- 95% dentro de 2œÉ
- 99.7% dentro de 3œÉ

**Threshold=3**: Marca como outliers el ~0.3% m√°s extremo (altamente at√≠picos).

#### 8.2 Aplicaci√≥n Multidimensional

En nuestro sistema:
```python
outlier(cliente) = True si CUALQUIER caracter√≠stica tiene |z_score| > 3
```

**Interpretaci√≥n**:
- Clientes con comportamiento extremo en al menos una dimensi√≥n RFM
- Ejemplos: Compra √∫nica masiva (Frequency=1, Monetary muy alto), Cliente VIP (todas m√©tricas extremas)

#### 8.3 Visualizaci√≥n

**Outliers en gr√°fico**:
- S√≠mbolo: Diamante (vs. c√≠rculo para normales)
- Tama√±o: M√°s grande (10 vs. 8 pixels)
- Borde: Negro grueso (mayor contraste)

**Prop√≥sito en BI**: Identificar casos especiales que requieren an√°lisis manual o estrategias personalizadas.

---

## Pipeline de Procesamiento y An√°lisis

El sistema implementa un pipeline ETL (Extract, Transform, Load) modular y escalable:

### Pipeline General

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      1. EXTRACCI√ìN DE DATOS                         ‚îÇ
‚îÇ  GitHub CSV ‚Üí Polars DataFrame (cached) ‚Üí Validaci√≥n y Limpieza    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    2. TRANSFORMACI√ìN DE DATOS                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Filtros Globales ‚îÇ ‚Üí ‚îÇ Feature Engineer ‚îÇ ‚Üí ‚îÇ Segmentaci√≥n    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Pa√≠s           ‚îÇ   ‚îÇ ‚Ä¢ C√°lculo Total  ‚îÇ   ‚îÇ ‚Ä¢ Detecci√≥n IQR ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Fechas         ‚îÇ   ‚îÇ ‚Ä¢ Parse dates    ‚îÇ   ‚îÇ ‚Ä¢ 4 Perfiles    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                              ‚îÇ
              ‚Üì                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3A. VISUALIZACIONES     ‚îÇ    ‚îÇ  3B. AN√ÅLISIS DE SIMILITUD        ‚îÇ
‚îÇ      B√ÅSICAS             ‚îÇ    ‚îÇ      (Pipeline Avanzado)          ‚îÇ
‚îÇ                          ‚îÇ    ‚îÇ                                   ‚îÇ
‚îÇ  ‚Ä¢ Mapa Mundial          ‚îÇ    ‚îÇ  Ver secci√≥n detallada abajo      ‚îÇ
‚îÇ  ‚Ä¢ Perfiles de Cliente   ‚îÇ    ‚îÇ                                   ‚îÇ
‚îÇ  ‚Ä¢ Tendencia de Ventas   ‚îÇ    ‚îÇ                                   ‚îÇ
‚îÇ  ‚Ä¢ Top Productos         ‚îÇ    ‚îÇ                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                                 ‚îÇ
               ‚Üì                                 ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               4. VISUALIZACI√ìN INTERACTIVA (Plotly.js)              ‚îÇ
‚îÇ  ‚Ä¢ Gr√°ficos responsivos  ‚Ä¢ Filtros din√°micos  ‚Ä¢ Tooltips enriquecidos‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pipeline de An√°lisis de Similitud de Clientes (Detallado)

Este es el **componente m√°s complejo y distintivo** del sistema:

```
PASO 1: PREPARACI√ìN DE CARACTER√çSTICAS RFM
‚îú‚îÄ‚îÄ Filtrar por pa√≠s y fechas (si se especifica)
‚îú‚îÄ‚îÄ Calcular fecha de referencia: max(InvoiceDate) + 1 d√≠a
‚îú‚îÄ‚îÄ Agregar por CustomerID:
‚îÇ   ‚îú‚îÄ‚îÄ Recency = D√≠as desde √∫ltima compra
‚îÇ   ‚îú‚îÄ‚îÄ Frequency = COUNT(DISTINCT InvoiceNo)
‚îÇ   ‚îú‚îÄ‚îÄ Monetary = SUM(Quantity √ó UnitPrice)
‚îÇ   ‚îú‚îÄ‚îÄ TotalQuantity = SUM(Quantity)
‚îÇ   ‚îú‚îÄ‚îÄ AvgUnitPrice = MEAN(UnitPrice)
‚îÇ   ‚îú‚îÄ‚îÄ AvgOrderValue = Monetary / Frequency
‚îÇ   ‚îî‚îÄ‚îÄ UniqueProducts = COUNT(DISTINCT StockCode)
‚îú‚îÄ‚îÄ Clasificar CustomerType usando IQR (4 perfiles)
‚îî‚îÄ‚îÄ Output: (customer_ids, feature_matrix[n√ó7], customer_info{})

PASO 2: NORMALIZACI√ìN
‚îú‚îÄ‚îÄ Opci√≥n A: Z-Score ‚Üí X' = (X-Œº)/œÉ
‚îú‚îÄ‚îÄ Opci√≥n B: Min-Max ‚Üí X' = (X-min)/(max-min)
‚îú‚îÄ‚îÄ Validaci√≥n: Detectar NaN/Inf ‚Üí Reemplazar
‚îî‚îÄ‚îÄ Output: features_normalized[n√ó7] (float32)

PASO 3: C√ÅLCULO DE MATRIZ DE DISTANCIAS
‚îú‚îÄ‚îÄ Opci√≥n A: Euclidiana ‚Üí d = ‚àöŒ£(x·µ¢-y·µ¢)¬≤
‚îú‚îÄ‚îÄ Opci√≥n B: Coseno ‚Üí d = 1 - cos(Œ∏)
‚îú‚îÄ‚îÄ Opci√≥n C: Pearson ‚Üí d = 1 - corr(x,y)
‚îú‚îÄ‚îÄ Optimizaciones: Broadcasting, operaciones in-place, gc
‚îî‚îÄ‚îÄ Output: distance_matrix[n√ón] (float32, sim√©trica)

PASO 4: B√öSQUEDA K-NEAREST NEIGHBORS
‚îú‚îÄ‚îÄ Para cliente seleccionado:
‚îÇ   ‚îú‚îÄ‚îÄ Extraer fila de distancias
‚îÇ   ‚îú‚îÄ‚îÄ Establecer distancia a s√≠ mismo = ‚àû
‚îÇ   ‚îú‚îÄ‚îÄ Ordenar distancias
‚îÇ   ‚îî‚îÄ‚îÄ Tomar primeros k √≠ndices
‚îú‚îÄ‚îÄ Crear aristas del grafo: source ‚Üí target
‚îú‚îÄ‚îÄ OPTIMIZACI√ìN: Liberar distance_matrix
‚îî‚îÄ‚îÄ Output: neighbor_indices[k], neighbor_distances[k], edges[]

PASO 5: REDUCCI√ìN DIMENSIONAL
‚îú‚îÄ‚îÄ Opci√≥n A: PCA (por defecto)
‚îÇ   ‚îú‚îÄ‚îÄ Centrar datos
‚îÇ   ‚îú‚îÄ‚îÄ SVD randomized
‚îÇ   ‚îú‚îÄ‚îÄ Proyectar a 2D
‚îÇ   ‚îú‚îÄ‚îÄ Calcular varianza explicada
‚îÇ   ‚îî‚îÄ‚îÄ Identificar top features por componente
‚îî‚îÄ‚îÄ Opci√≥n B: Ejes directos (x_axis, y_axis)
‚îî‚îÄ‚îÄ Output: embedding_2d[n√ó2], pca_variance{} o axis_info{}

PASO 6: CLUSTERING K-MEANS
‚îú‚îÄ‚îÄ K-Means con k=4 (alineado a perfiles RFM)
‚îú‚îÄ‚îÄ Inicializaci√≥n k-means++
‚îú‚îÄ‚îÄ Algoritmo Elkan (optimizado)
‚îî‚îÄ‚îÄ Output: cluster_labels[n] (int32, valores 0-3)

PASO 7: DETECCI√ìN DE OUTLIERS
‚îú‚îÄ‚îÄ Calcular Z-scores multidimensional
‚îú‚îÄ‚îÄ Marcar outlier si any(z > 3)
‚îî‚îÄ‚îÄ Output: outlier_mask[n] (boolean)

PASO 8: PREPARACI√ìN PARA VISUALIZACI√ìN
‚îú‚îÄ‚îÄ embedding_data[]: {id, x, y, cluster, outlier, customer_type, ...}
‚îú‚îÄ‚îÄ neighbors_data[]: {id, distance, rank}
‚îú‚îÄ‚îÄ edges_data[]: {source, target}
‚îî‚îÄ‚îÄ Output: JSON serializable para frontend

PASO 9: GENERACI√ìN DE GR√ÅFICO PLOTLY
‚îú‚îÄ‚îÄ Capas (orden):
‚îÇ   ‚îú‚îÄ‚îÄ 1. Aristas (l√≠neas grises)
‚îÇ   ‚îú‚îÄ‚îÄ 2. Puntos normales (c√≠rculos, por cluster)
‚îÇ   ‚îú‚îÄ‚îÄ 3. Outliers (diamantes)
‚îÇ   ‚îú‚îÄ‚îÄ 4. Vecinos (borde amarillo)
‚îÇ   ‚îî‚îÄ‚îÄ 5. Cliente seleccionado (estrella roja)
‚îú‚îÄ‚îÄ Paleta de 4 colores para clusters
‚îú‚îÄ‚îÄ Leyenda: "Cluster X: Tipo (Y%)"
‚îî‚îÄ‚îÄ Output: Plotly Figure (JSON)

PASO 10: RENDERIZADO WEB
‚îú‚îÄ‚îÄ Backend: Serializar con PlotlyJSONEncoder
‚îú‚îÄ‚îÄ Frontend: Parsear y renderizar con Plotly.newPlot()
‚îî‚îÄ‚îÄ M√©tricas: n=1000 ‚Üí 2-3s, n=5000 ‚Üí 8-12s
```

### Optimizaciones de Performance Implementadas

El sistema est√° optimizado para despliegue en **Railway** (recursos limitados):

1. **Gesti√≥n de Memoria**:
   - Uso de `float32` en vez de `float64` (50% menos memoria)
   - Liberaci√≥n agresiva con `gc.collect()` despu√©s de operaciones pesadas
   - Operaciones numpy in-place (`out=` parameter)

2. **Algoritmos Eficientes**:
   - PCA con `svd_solver='randomized'` (m√°s r√°pido para n>1000)
   - K-Means con `algorithm='elkan'` (evita c√°lculos redundantes)
   - Reducci√≥n de iteraciones: `max_iter=50`, `n_init=5`

3. **Cach√©**:
   - Carga de datos con `@lru_cache` (evita descargas repetidas del CSV)
   - Reutilizaci√≥n de DataFrames entre visualizaciones

4. **Procesamiento Vectorizado**:
   - Uso intensivo de operaciones numpy/polars vectorizadas
   - Evitar loops de Python cuando sea posible

---

## Modelos y Algoritmos Implementados

### 1. Modelo de Segmentaci√≥n RFM con IQR

**Descripci√≥n**: Sistema de clasificaci√≥n de clientes en 4 perfiles de negocio.

**Entrenamiento**: No requiere entrenamiento (m√©todo basado en reglas estad√≠sticas).

**Componentes**:
- Detecci√≥n de outliers en dimensi√≥n `Total` (Q1, Q3, IQR)
- Detecci√≥n de outliers en dimensi√≥n `UnitPrice`
- L√≥gica combinatoria para asignar perfil

**Diferenciaci√≥n**:
- M√©todos tradicionales usan percentiles fijos (ej: top 20% = VIP)
- Nuestro modelo usa IQR **adaptativo** que se ajusta a la distribuci√≥n real de cada dataset/pa√≠s/per√≠odo
- Captura outliers en 2 dimensiones complementarias (volumen vs. precio)

**Ventajas**:
- ‚úÖ Robusto ante cambios en distribuci√≥n de datos
- ‚úÖ Interpretabilidad de negocio directa
- ‚úÖ No requiere datos hist√≥ricos (funciona con snapshot)

**Limitaciones**:
- ‚ö†Ô∏è Asume independencia entre Total y UnitPrice (puede haber correlaci√≥n)
- ‚ö†Ô∏è Fronteras r√≠gidas (no captura gradientes suaves)

### 2. Modelo de Similitud de Clientes (Graph-based KNN)

**Descripci√≥n**: Sistema de aprendizaje no supervisado que construye un grafo de similitud entre clientes basado en comportamiento RFM.

**Arquitectura del Modelo**:

```
Input (7 dimensiones RFM)
         ‚Üì
Normalizaci√≥n (Z-Score/MinMax)
         ‚Üì
Espacio M√©trico (Euclidean/Cosine/Pearson)
         ‚Üì
Grafo KNN (k vecinos m√°s cercanos)
         ‚Üì
Proyecci√≥n 2D (PCA)
         ‚Üì
Clusters (K-Means, k=4)
         ‚Üì
Output (Visualizaci√≥n interactiva)
```

**Entrenamiento**:
- **K-Means**: Algoritmo de Lloyd con inicializaci√≥n k-means++
- **PCA**: Descomposici√≥n en valores singulares (SVD)
- **Ambos son "unsupervised"**: No requieren etiquetas, descubren patrones inherentes

**Inferencia**:
- Para nuevo cliente: Calcular caracter√≠sticas RFM ‚Üí Normalizar ‚Üí Encontrar k vecinos en grafo ‚Üí Asignar cluster m√°s cercano

**Diferenciaci√≥n de Modelos Existentes**:

| Aspecto | Sistemas Tradicionales | Nuestro Modelo |
|---------|------------------------|----------------|
| Dimensionalidad | RFM b√°sico (3D) | RFM extendido (7D) |
| M√©trica | Solo Euclidiana | 3 m√©tricas configurables |
| Visualizaci√≥n | 3D est√°tico o 2D simple | 2D con PCA interpretable |
| Clustering | K-Means standalone | K-Means + validaci√≥n con perfiles IQR |
| Outliers | Ignorados o removidos | Detectados y visualizados (valiosos) |
| Interactividad | Tablas/dashboards est√°ticos | Filtros din√°micos + drill-down |
| Escalabilidad | Problemas con n>10k | Optimizado para Railway (float32, SVD randomized) |

**Ejemplo de Caso de Uso**:

Imaginemos un cliente `12345` clasificado como "Minorista Lujo":
1. Sistema calcula sus k=10 vecinos m√°s cercanos
2. Encuentra que 7/10 tambi√©n son "Minorista Lujo", 2 "Mayorista Lujo", 1 "Minorista Est√°ndar"
3. **Insight de negocio**: Este cliente tiene potencial de upgrade a "Mayorista Lujo" (2 vecinos similares ya lo son)
4. **Acci√≥n**: Ofrecerle descuentos por volumen o membres√≠a mayorista
5. **Recomendaci√≥n de productos**: Analizar top productos de sus 10 vecinos ‚Üí productos que a√∫n no ha comprado

### 3. Integraci√≥n de Modelos

**Punto clave**: Los dos modelos (RFM-IQR y KNN-Clustering) se **complementan**, no compiten:

- **RFM-IQR**: Da interpretaci√≥n de negocio (qu√© tipo de cliente es)
- **KNN-Clustering**: Da contexto anal√≠tico (con qu√© otros clientes se comporta similar)

**Validaci√≥n cruzada**:
- Esperamos que clusters tengan composici√≥n predominante de ciertos perfiles RFM
- Si Cluster 2 es 80% "Mayorista Est√°ndar" ‚Üí confirma que el clustering captura patrones reales de negocio
- Si clusters tienen mezcla uniforme ‚Üí indica que las 7 dimensiones RFM capturan informaci√≥n ortogonal a Total/UnitPrice

---

## Arquitectura del Sistema

### Stack Tecnol√≥gico

**Backend**:
- Django 5.2.8 (Framework web MVC)
- Polars (DataFrame library, m√°s r√°pido que Pandas para datasets grandes)
- NumPy, SciPy (Computaci√≥n num√©rica)
- scikit-learn (Algoritmos de ML: PCA, K-Means)
- Plotly (Generaci√≥n de gr√°ficos)

**Frontend**:
- HTML5/CSS3
- JavaScript (ES6+)
- Plotly.js (Renderizado interactivo de gr√°ficos)

**Despliegue**:
- Gunicorn (WSGI server)
- WhiteNoise (Servir archivos est√°ticos)
- Railway (PaaS: PostgreSQL, auto-deploy desde Git)

**Datos**:
- Fuente: CSV en GitHub (p√∫blico)
- Producci√≥n: PostgreSQL (Railway)
- Desarrollo: SQLite

### Estructura Modular

```
online-retail-vizualizacion/
‚îú‚îÄ‚îÄ core/                          # Configuraci√≥n Django
‚îÇ   ‚îú‚îÄ‚îÄ settings.py                # SQLite (dev), PostgreSQL (prod)
‚îÇ   ‚îú‚îÄ‚îÄ urls.py                    # Rutas API
‚îÇ   ‚îî‚îÄ‚îÄ wsgi.py
‚îú‚îÄ‚îÄ dashboard/                     # Aplicaci√≥n principal
‚îÇ   ‚îú‚îÄ‚îÄ views.py                   # Orquestador HTTP (API endpoints)
‚îÇ   ‚îú‚îÄ‚îÄ templates/index.html       # Single-page application
‚îÇ   ‚îú‚îÄ‚îÄ static/visualizaciones/    # Frontend JS/CSS
‚îÇ   ‚îî‚îÄ‚îÄ visualizations/            # M√≥dulos de procesamiento
‚îÇ       ‚îú‚îÄ‚îÄ shared/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ data_loader.py     # Carga CSV con cach√©
‚îÇ       ‚îú‚îÄ‚îÄ world_map/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ plot.py
‚îÇ       ‚îú‚îÄ‚îÄ customer_profiles/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py  # Detecci√≥n IQR
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ plot.py
‚îÇ       ‚îú‚îÄ‚îÄ sales/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ plot.py
‚îÇ       ‚îú‚îÄ‚îÄ products/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ plot.py
‚îÇ       ‚îî‚îÄ‚îÄ client_similarity/     # Pipeline complejo
‚îÇ           ‚îú‚îÄ‚îÄ data_processor.py  # Orquestador principal
‚îÇ           ‚îú‚îÄ‚îÄ preprocessing.py   # Normalizaci√≥n
‚îÇ           ‚îú‚îÄ‚îÄ distances.py       # Matrices de distancia
‚îÇ           ‚îú‚îÄ‚îÄ knn.py             # K-vecinos y grafo
‚îÇ           ‚îú‚îÄ‚îÄ dimensionality.py  # PCA
‚îÇ           ‚îú‚îÄ‚îÄ clustering.py      # K-Means, outliers
‚îÇ           ‚îî‚îÄ‚îÄ plot.py            # Visualizaci√≥n Plotly
‚îú‚îÄ‚îÄ manage.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ Procfile                       # Railway deployment
‚îî‚îÄ‚îÄ README.md
```

---

## Comparaci√≥n con Enfoques Existentes

### 1. An√°lisis RFM Tradicional

**Enfoque est√°ndar**:
- Divisi√≥n en quintiles (5 grupos) para R, F, M
- Asignaci√≥n de score 1-5 a cada dimensi√≥n
- Concatenaci√≥n: Cliente con R=5, F=4, M=5 ‚Üí "545"
- 125 segmentos posibles (5¬≥)

**Limitaciones**:
- ‚ùå Demasiados segmentos (dificulta acci√≥n)
- ‚ùå No considera distribuci√≥n real (outliers mal manejados)
- ‚ùå Fronteras arbitrarias (quintiles pueden ser similares)

**Nuestro enfoque**:
- ‚úÖ IQR adaptativo (se ajusta a distribuci√≥n)
- ‚úÖ 4 segmentos accionables (alineados con estrategias de negocio)
- ‚úÖ Combina RFM con precio unitario (captura lujo vs. est√°ndar)
- ‚úÖ Validaci√≥n con clustering no supervisado

### 2. Herramientas de BI Comerciales (Tableau, Power BI)

**Tableau/Power BI**:
- Drag-and-drop para crear visualizaciones
- Conectores a m√∫ltiples fuentes de datos
- Dashboards interactivos

**Limitaciones**:
- ‚ùå Algoritmos de ML limitados (requieren R/Python integrado)
- ‚ùå Costo (licencias por usuario)
- ‚ùå Menor control sobre pipeline de datos

**Nuestro enfoque**:
- ‚úÖ Pipeline de ML completo en c√≥digo (reproducible, versionable)
- ‚úÖ Open-source (sin costos de licencia)
- ‚úÖ Totalmente customizable (podemos agregar nuevos algoritmos)
- ‚úÖ Integraci√≥n nativa con Django (autenticaci√≥n, permisos futuros)
- ‚ö†Ô∏è Requiere conocimientos t√©cnicos (no drag-and-drop)

---

## Instalaci√≥n y Uso

### Requisitos Previos

- Python 3.11+
- pip (gestor de paquetes)
- Git

### Instalaci√≥n Local

```bash
# 1. Clonar repositorio
git clone https://github.com/tu-usuario/online-retail-vizualizacion.git
cd online-retail-vizualizacion

# 2. Crear entorno virtual
python -m venv venv

# 3. Activar entorno virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 4. Instalar dependencias
pip install -r requirements.txt

# 5. Aplicar migraciones
python manage.py migrate

# 6. Ejecutar servidor de desarrollo
python manage.py runserver

# 7. Abrir en navegador
# http://127.0.0.1:8000/
```

### Uso de la Aplicaci√≥n

#### 1. Visualizaciones B√°sicas

Al cargar la p√°gina principal, ver√°s 4 visualizaciones iniciales:

1. **Mapa Mundial**: Ventas por pa√≠s (choropleth)
   - Click en pa√≠s ‚Üí Filtra todas las dem√°s visualizaciones
   - Hover ‚Üí Muestra ventas totales del pa√≠s

2. **Perfiles de Cliente**: Barras horizontales con 4 segmentos
   - Click en barra ‚Üí Filtra por perfil de cliente
   - Colores alineados con tipos de cliente

3. **Tendencia de Ventas**: L√≠nea temporal
   - Muestra ventas mensuales
   - Se actualiza seg√∫n filtros de pa√≠s/perfil/fechas

4. **Top 5 Productos**: Barras horizontales
   - Productos m√°s vendidos
   - Filtrable por categor√≠a/subcategor√≠a

#### 2. An√°lisis de Similitud de Clientes

**Panel de configuraci√≥n**:

1. Seleccionar Customer ID (autocompletado con IDs disponibles)
2. Configurar par√°metros:
   - **K vecinos**: N√∫mero de clientes similares a mostrar (1-500)
   - **M√©trica de distancia**: Euclidiana (diferencias absolutas), Coseno (patrones), Pearson (correlaciones)
   - **Normalizaci√≥n**: Z-Score (recomendado), Min-Max
   - **Ejes**: PCA (autom√°tico) o Caracter√≠sticas directas (Recency, Frequency, etc.)
3. Aplicar filtros globales (opcional):
   - Pa√≠s
   - Rango de fechas
4. Click "Calcular Similitud"

**Interpretaci√≥n del gr√°fico**:

- **Puntos**: Cada punto = 1 cliente
- **Colores**: 4 colores = 4 clusters (grupos de comportamiento similar)
- **Formas**:
  - C√≠rculo: Cliente normal
  - Diamante: Outlier (comportamiento at√≠pico)
  - Estrella roja: Cliente seleccionado
- **L√≠neas**: Conexiones entre cliente seleccionado y sus k vecinos
- **Ejes**:
  - Si PCA: "Caracter√≠stica_Principal (% varianza)"
  - Si directo: Nombre de la caracter√≠stica RFM

---

## Referencias

### Fundamentos Te√≥ricos

1. **RFM Analysis**:
   - Bult, J. R., & Wansbeek, T. (1995). "Optimal Selection for Direct Mail." Marketing Science, 14(4), 378-394.
   - Fader, P. S., Hardie, B. G., & Lee, K. L. (2005). "RFM and CLV: Using Iso-Value Curves for Customer Base Analysis." Journal of Marketing Research, 42(4), 415-430.

2. **Outlier Detection (IQR)**:
   - Tukey, J. W. (1977). "Exploratory Data Analysis." Addison-Wesley.

3. **Distance Metrics**:
   - Deza, M. M., & Deza, E. (2009). "Encyclopedia of Distances." Springer.

4. **K-Nearest Neighbors**:
   - Cover, T., & Hart, P. (1967). "Nearest Neighbor Pattern Classification." IEEE Transactions on Information Theory, 13(1), 21-27.

5. **Principal Component Analysis**:
   - Jolliffe, I. T. (2002). "Principal Component Analysis." Springer Series in Statistics, 2nd Edition.
   - Halko, N., Martinsson, P. G., & Tropp, J. A. (2011). "Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions." SIAM Review, 53(2), 217-288.

6. **K-Means Clustering**:
   - MacQueen, J. (1967). "Some Methods for Classification and Analysis of Multivariate Observations." Proceedings of 5th Berkeley Symposium.
   - Arthur, D., & Vassilvitskii, S. (2007). "k-means++: The Advantages of Careful Seeding." SODA '07.

---

## Metadatos del Proyecto

**Curso**: Inteligencia de Negocios y Miner√≠a de Datos
**Instituci√≥n**: Universidad La Salle de Arequipa
**Semestre**: 2025 II
**Profesora**: Ana Mar√≠a Cuadros Valdivia

**Dataset**:
- Fuente: UCI Machine Learning Repository - Online Retail Dataset
- URL: https://archive.ics.uci.edu/ml/datasets/Online+Retail
- Per√≠odo: 01/12/2010 - 09/12/2011
- Registros: ~541,909 transacciones
- Clientes: ~4,372 √∫nicos
- Pa√≠ses: 38

---

**√öltima actualizaci√≥n**: 28 de noviembre de 2025
